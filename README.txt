=========Где брать документацию=========
по nVidia не пишу. Они большие популяризаторы developer.nvidia.com, у них кстати классный форум там.
google - Best Practices Guide GPU и вы в первую очередь на CUDA и nVidia.

С OpenCL как и со всем опен всё не так прямолинейно.
Вопервых OpenCL это кусочек стандартов Khronos group
тоесть все что касается языка OpenCL надо искать тут https://www.khronos.org/opencl/
например
типы данных:
https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/scalarDataTypes.html
функции потока
https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/workItemFunctions.html
Это языковая часть. Не стоит там искать методов оптимизации.

Что касается устройств AMD тоесть для файн тюнинга (без которого с GPU впрочем и смысла нет):
https://developer.amd.com/amd-accelerated-parallel-processing-app-sdk/
http://developer.amd.com/wordpress/media/2013/12/AMD_OpenCL_Programming_Optimization_Guide2.pdf
(имеет смысл скачать pdf так как html версия глюкаво показывает картинки, схемы и даже таблицы)

Одна мелкая полезная ссылка по кодам ошибок (кажется я провёл тут больше всего времени)
https://streamhpc.com/blog/2013-04-28/opencl-error-codes/


=========Пакет кодов к тренингу===========
Я добавил кучу коментов с псевдографикой(псевдосхемами). Основной упор получился на OpenCL,
поэтому аннотирован именно этот код. Из отличий от AMD у nVidia нет проблем с канальностью памяти, +nVidia сильно тормозит на делении с плавающей точкой в остальном тендеции похожи.
Обычно в nVidia надо брать гораздо большее количество активных блоков чем в AMD.
*Если ктото готов запустить эти OpenCL тесты на платформе nVidia прошу сообщить о результатах, особенно если это будут топовые 600 и 700 серии ускорителей. тогда мы сможем сравить производительность с примерно эквивалентным 7970-м Radeon-ом.

Все тесты написаны под Linux. Система сборки примитивная - bash скриптом, что впрочем полезно для понимания как собирать с нуля.
Чтобы собрать тест имеет смысл открыть run или build скрипт, посмотреть что он делает, возможно поправить пути, и в бой.
*для nVidia перед сборкой нужно проверить, что ваша карта поддерживает Compute Capability (у меня там кажется 3.0 стоит по дефолту).

Прошу прощения за отсутсвие схем устройства GPU и последовательности запуска задач, но они уже 100 раз нарисованы в любом руководстве (советую nVidia, так как у них, как уже отмечалось, рука набита на популяризации GPGPU).
В сухом остатке для разработки вы должны помнить 3 вещи:
1. coalesced чтение/запись памяти
2. если 1 никак не выполнить вам точно нужна shared память. у неё тоже есть банки, помним об этом и разрабатываем правильный паттерн доступа.
3. конвеер = occupancy(это слово на каждой странице nVidia Best Practices, но понять зачем оно вам надо, можно только поняв, почему без конвеера все будет работать весьма угрюмо) = разделение ресурсов.
это 3 связанных понятия. вы должны закидать на устройство больше задач, чем у него имеется физических исполнительных юнитов, чтобы загрузить конвеер, при этом вы должны следить, что все ваши задачи МОГУТ одновременно исполняться и ЗАГРУЗЯТ таки конвеер. для этого им должно хватить ресурсов (помните в этом неприятном смысле всё общее и локальная память и регистры).

*На тренинге случилась заминка с таймингами. Все ядра вдруг стали работать значительно хуже.
 Это моя проблема я забыл что в предыдущем запуске я показывал неоптимальную конфигурацию запуска (малое число блоков)
 Вобщем прежде чем продолжать с блочным чтением и каналами надо было вернуть обратно общее количество блоков.

**Если появится группа желающая снова обсудить разработку для GPU мы можем неформально собраться в томже зуме, а можно и живьем в Ауриге (только нам надо будет доступ к тачке с интересующими вас девайсами).


===========ссылки на развлекательные ресурсы==========
*тут вы врятли почерпнёте практические знания, но тем не менее...
приключения электромагниного волнового пакета и идеальной электронной плазмы с GPU:
https://www.youtube.com/watch?v=qbYcXZ_zoWQ
https://www.youtube.com/watch?v=TD4XnEgjhFk

резиновый кубик из пружинок
(ужасно тормозная вещь ибо связи кубиков дурацкие и доступ к памяти получился плохой)
https://www.youtube.com/watch?v=1B6FeWbg1wY
https://www.youtube.com/watch?v=dof7bbHQAV0

как пробивался воздух с помощью небольшого численного кода и GPU (на самом деле жуткий код который шарить смысла нет):
https://www.youtube.com/watch?v=epEUqBdbUhs
видео сделано по мотивам работы описанной в статье.
в ней рассказано не только как интегрировать
но и как делать прогонку для обращения трёхдиагональной матрицы! а может там и нет про интегрирование
в любом случае прогонка даже интереснее. собственно вот ссылка:
https://www.sciencedirect.com/science/article/pii/S1877750312000920

и кстати по плану Ауриговского саморазвития я должен был ещё про NUMA рассказать.
это достаточно тривиальная, но весьма актуальная вещь для всех современных рабочих станций x86
вот статья http://www.computeroptics.ru/jour/article/view/402
в контекст GPU девелопмента NUMA органично вливается потому, что многопроцессорные рабочие станции уже нельзя рассматривать в модели N ядер + одна большая общая память и все равны.

если чтото не качается, пишите - пороюсь, найду, пришлю.
